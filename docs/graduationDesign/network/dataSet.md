# 数据集

- [About](http://rodrigob.github.io/are_we_there_yet/build/#about)
- [Datasets](http://rodrigob.github.io/are_we_there_yet/build/#datasets)
- [Contact](http://rodrigob.github.com/#contact)

### Classification datasets results

------

# What is the class of this image ?

Discover the current state of the art in objects classification.

- [MNIST](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354)
- [CIFAR-10](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)
- [CIFAR-100](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d313030)
- [STL-10](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130)
- [SVHN](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#5356484e)
- [ILSVRC2012 task 1](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#494c5356524332303132207461736b2031)

# MNIST who is the best in MNIST ?

- [![img](http://rodrigob.github.io/are_we_there_yet/build/images/mnist.png?1363085077)](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354)

### [MNIST](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#4d4e495354) 50 results collected

Units: error %

> [Classify handwriten digits](http://yann.lecun.com/exdb/mnist/). Some additional results are available on the [original dataset page](http://yann.lecun.com/exdb/mnist/).

| Result | Method                                                       | Venue                                   | Details |
| :----- | :----------------------------------------------------------- | :-------------------------------------- | :------ |
| 0.21%  | [Regularization of Neural Networks using DropConnect](http://cs.nyu.edu/~wanli/dropc/) | ICML 2013                               |         |
| 0.23%  | [Multi-column Deep Neural Networks for Image Classiﬁcation](http://www.idsia.ch/~ciresan/data/cvpr2012.pdf) | CVPR 2012                               |         |
| 0.23%  | [APAC: Augmented PAttern Classification with Neural Networks](http://arxiv.org/abs/1505.03229) | arXiv 2015                              |         |
| 0.24%  | [Batch-normalized Maxout Network in Network](http://arxiv.org/abs/1511.02583) | arXiv 2015                              | Details |
| 0.29%  | [Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree](http://arxiv.org/abs/1509.08985) | AISTATS 2016                            | Details |
| 0.31%  | [Recurrent Convolutional Neural Network for Object Recognition](http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf) | CVPR 2015                               |         |
| 0.31%  | [On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units](http://arxiv.org/abs/1508.00330) | arXiv 2015                              |         |
| 0.32%  | [Fractional Max-Pooling](http://arxiv.org/abs/1412.6071)     | arXiv 2015                              | Details |
| 0.33%  | [Competitive Multi-scale Convolution](http://arxiv.org/abs/1511.05635) | arXiv 2015                              |         |
| 0.35%  | [Deep Big Simple Neural Nets Excel on Handwritten Digit Recognition](http://arxiv.org/pdf/1003.0358.pdf) | Neural Computation 2010                 | Details |
| 0.35%  | [C-SVDDNet: An Effective Single-Layer Network for Unsupervised Feature Learning](http://arxiv.org/abs/1412.7259) | arXiv 2014                              |         |
| 0.37%  | [Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network](http://arxiv.org/abs/1503.04596) | arXiv 2015                              | Details |
| 0.39%  | [Efﬁcient Learning of Sparse Representations with an Energy-Based Model](http://papers.nips.cc/paper/3112-efficient-learning-of-sparse-representations-with-an-energy-based-model) | NIPS 2006                               | Details |
| 0.39%  | [Convolutional Kernel Networks](http://arxiv.org/abs/1406.3332) | arXiv 2014                              | Details |
| 0.39%  | [Deeply-Supervised Nets](http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/) | arXiv 2014                              |         |
| 0.4%   | [Best Practices for Convolutional Neural Networks Applied to Visual Document Analysis](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=D1C7D701BD39935473808DA5A93426C5?doi=10.1.1.160.8494&rep=rep1&type=pdf) | Document Analysis and Recognition 2003  |         |
| 0.40%  | [Hybrid Orthogonal Projection and Estimation (HOPE): A New Framework to Probe and Learn Neural Networks](http://arxiv.org/pdf/1502.00702.pdf) | arXiv 2015                              |         |
| 0.42%  | [Multi-Loss Regularized Deep Neural Network](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343) | CSVT 2015                               | Details |
| 0.45%  | [Maxout Networks](http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf) | ICML 2013                               | Details |
| 0.45%  | [Training Very Deep Networks](http://people.idsia.ch/~rupesh/very_deep_learning/) | NIPS 2015                               | Details |
| 0.45%  | [ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks](http://arxiv.org/abs/1505.00393) | arXiv 2015                              |         |
| 0.46%  | [Deep Convolutional Neural Networks as Generic Feature Extractors](http://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf) | IJCNN 2015                              | Details |
| 0.47%  | [Network in Network](http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea) | ICLR 2014                               | Details |
| 0.52 % | [Trainable COSFIRE filters for keypoint detection and pattern recognition](http://iwi.eldoc.ub.rug.nl/FILES/root/2013/IEEETPAMIAzzopardi/2013IEEETPAMIAzzopardi.pdf) | PAMI 2013                               | Details |
| 0.53%  | [What is the Best Multi-Stage Architecture for Object Recognition?](http://yann.lecun.com/exdb/publis/pdf/jarrett-iccv-09.pdf) | ICCV 2009                               | Details |
| 0.54%  | [Deformation Models for Image Recognition](http://www.keysers.net/daniel/files/Keysers--Deformation-Models--TPAMI2007.pdf) | PAMI 2007                               | Details |
| 0.54%  | [A trainable feature extractor for handwritten digit recognition](http://hal.inria.fr/docs/00/05/75/61/PDF/LauerSuenBlochPR.pdf) | Journal Pattern Recognition 2007        | Details |
| 0.56%  | [Training Invariant Support Vector Machines](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.88.9924&rep=rep1&type=pdf) | Machine Learning 2002                   | Details |
| 0.59%  | [Simple Methods for High-Performance Digit Recognition Based on Sparse Coding](http://www.inb.uni-luebeck.de/publikationen/pdfs/LaBaMa08c.pdf) | TNN 2008                                | Details |
| 0.62%  | [Unsupervised learning of invariant feature hierarchies with applications to object recognition](http://yann.lecun.com/exdb/publis/pdf/ranzato-cvpr-07.pdf) | CVPR 2007                               | Details |
| 0.62%  | [PCANet: A Simple Deep Learning Baseline for Image Classification?](http://arxiv.org/abs/1404.3606) | arXiv 2014                              | Details |
| 0.63%  | [Shape matching and object recognition using shape contexts](http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=B2AAC2BC3824F19757CAC66986D5F3FF?doi=10.1.1.18.8852&rep=rep1&type=pdf) | PAMI 2002                               | Details |
| 0.64%  | [Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features](http://www.icsi.berkeley.edu/pubs/vision/beyondspatial12.pdf) | CVPR 2012                               |         |
| 0.68%  | [Handwritten Digit Recognition using Convolutional Neural Networks and Gabor Filters](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.133.6559&rep=rep1&type=pdf) | ICCI 2003                               |         |
| 0.69%  | [On Optimization Methods for Deep Learning](http://ai.stanford.edu/~quocle/LeNgiCoaLahProNg11.pdf) | ICML 2011                               |         |
| 0.71%  | [Deep Fried Convnets](http://www.cv-foundation.org/openaccess/content_iccv_2015/papers/Yang_Deep_Fried_Convnets_ICCV_2015_paper.pdf) | ICCV 2015                               | Details |
| 0.75%  | [Sparse Activity and Sparse Connectivity in Supervised Learning](http://jmlr.org/papers/v14/thom13a.html) | JMLR 2013                               |         |
| 0.78%  | [Explaining and Harnessing Adversarial Examples](http://arxiv.org/abs/1412.6572) | ICLR 2015                               | Details |
| 0.82%  | Convolutional Deep Belief Networks for Scalable Unsupervised Learning of Hierarchical Representations | ICML 2009                               |         |
| 0.84%  | [Supervised Translation-Invariant Sparse Coding](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.206.339&rep=rep1&type=pdf) | CVPR 2010                               | Details |
| 0.94%  | Large-Margin kNN Classification using a Deep Encoder Network | 2009                                    |         |
| 0.95%  | [Deep Boltzmann Machines](http://www.utstat.toronto.edu/~rsalakhu/papers/dbm.pdf) | AISTATS 2009                            |         |
| 1.01%  | [BinaryConnect: Training Deep Neural Networks with binary weights during propagations](http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf) | NIPS 2015                               | Details |
| 1.1%   | [StrongNet: mostly unsupervised image recognition with strong neurons](http://www.alglib.net/articles/tr-20140813-strongnet.pdf) | technical report on ALGLIB website 2014 | Details |
| 1.12%  | CS81: Learning words with Deep Belief Networks               | 2008                                    |         |
| 1.19%  | Convolutional Neural Networks                                | 2003                                    | Details |
| 1.2%   | Reducing the dimensionality of data with neural networks     | 2006                                    |         |
| 1.40%  | [Convolutional Clustering for Unsupervised Learning](http://arxiv.org/abs/1511.06241) | arXiv 2015                              | Details |
| 1.5%   | Deep learning via semi-supervised embedding                  | 2008                                    |         |
| 14.53% | [Deep Representation Learning with Target Coding](http://personal.ie.cuhk.edu.hk/~ccloy/files/aaai_2015_target_coding.pdf) | AAAI 2015                               |         |

Something is off, something is missing ? Feel free to [fill in the form](http://rodrigob.github.io/are_we_there_yet/build/new_result_form.html).

# CIFAR-10 who is the best in CIFAR-10 ?

- [![img](http://rodrigob.github.io/are_we_there_yet/build/images/cifar_10.png?1363085077)](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130)

### [CIFAR-10](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130) 49 results collected

Units: accuracy %

> Classify [32x32 colour images](http://www.cs.toronto.edu/~kriz/cifar.html).

| Result  | Method                                                       | Venue              | Details |
| :------ | :----------------------------------------------------------- | :----------------- | :------ |
| 96.53%  | [Fractional Max-Pooling](http://arxiv.org/abs/1412.6071)     | arXiv 2015         | Details |
| 95.59%  | [Striving for Simplicity: The All Convolutional Net](http://arxiv.org/pdf/1412.6806.pdf) | ICLR 2015          | Details |
| 94.16%  | [All you need is a good init](http://arxiv.org/abs/1511.06422) | ICLR 2016          | Details |
| 94%     | [Lessons learned from manually classifying CIFAR-10](http://karpathy.github.io/2011/04/27/manually-classifying-cifar10/) | unpublished 2011   | Details |
| 93.95%  | [Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree](http://arxiv.org/abs/1509.08985) | AISTATS 2016       | Details |
| 93.72%  | [Spatially-sparse convolutional neural networks](http://arxiv.org/abs/1409.6070) | arXiv 2014         |         |
| 93.63%  | [Scalable Bayesian Optimization Using Deep Neural Networks](http://arxiv.org/abs/1502.05700) | ICML 2015          |         |
| 93.57%  | [Deep Residual Learning for Image Recognition](http://arxiv.org/abs/1512.03385) | arXiv 2015         | Details |
| 93.45%  | [Fast and Accurate Deep Network Learning by Exponential Linear Units](http://arxiv.org/abs/1511.07289) | arXiv 2015         | Details |
| 93.34%  | [Universum Prescription: Regularization using Unlabeled Data](http://arxiv.org/abs/1511.03719) | arXiv 2015         |         |
| 93.25%  | [Batch-normalized Maxout Network in Network](http://arxiv.org/abs/1511.02583) | arXiv 2015         | Details |
| 93.13%  | [Competitive Multi-scale Convolution](http://arxiv.org/abs/1511.05635) | arXiv 2015         |         |
| 92.91%  | [Recurrent Convolutional Neural Network for Object Recognition](http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf) | CVPR 2015          | Details |
| 92.49%  | [Learning Activation Functions to Improve Deep Neural Networks](http://arxiv.org/abs/1412.6830) | ICLR 2015          | Details |
| 92.45%  | [cifar.torch](http://torch.ch/blog/2015/07/30/cifar.html)    | unpublished 2015   | Details |
| 92.40%  | [Training Very Deep Networks](http://people.idsia.ch/~rupesh/very_deep_learning/) | NIPS 2015          | Details |
| 92.23%  | [Stacked What-Where Auto-encoders](http://arxiv.org/abs/1506.02351) | arXiv 2015         |         |
| 91.88%  | [Multi-Loss Regularized Deep Neural Network](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343) | CSVT 2015          | Details |
| 91.78%  | [Deeply-Supervised Nets](http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/) | arXiv 2014         | Details |
| 91.73%  | [BinaryConnect: Training Deep Neural Networks with binary weights during propagations](http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf) | NIPS 2015          | Details |
| 91.48%  | [On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units](http://arxiv.org/abs/1508.00330) | arXiv 2015         |         |
| 91.40%  | [Spectral Representations for Convolutional Neural Networks](http://papers.nips.cc/paper/5649-spectral-representations-for-convolutional-neural-networks.pdf) | NIPS 2015          |         |
| 91.2%   | [Network In Network](http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea) | ICLR 2014          | Details |
| 91.19%  | [Speeding up Automatic Hyperparameter Optimization of Deep Neural Networks by Extrapolation of Learning Curves](http://aad.informatik.uni-freiburg.de/papers/15-IJCAI-Extrapolation_of_Learning_Curves.pdf) | IJCAI 2015         | Details |
| 90.78%  | [Deep Networks with Internal Selective Attention through Feedback Connections](http://papers.nips.cc/paper/5276-deep-networks-with-internal-selective-attention-through-feedback-connections.pdf) | NIPS 2014          | Details |
| 90.68%  | [Regularization of Neural Networks using DropConnect](http://cs.nyu.edu/~wanli/dropc/) | ICML 2013          |         |
| 90.65%  | [Maxout Networks](http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf) | ICML 2013          | Details |
| 90.61%  | [Improving Deep Neural Networks with Probabilistic Maxout Units](http://openreview.net/document/28d9c3ab-fe88-4836-b898-403d207a037c#28d9c3ab-fe88-4836-b898-403d207a037c) | ICLR 2014          | Details |
| 90.5%   | [Practical Bayesian Optimization of Machine Learning Algorithms](http://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf) | NIPS 2012          | Details |
| 89.67%  | [APAC: Augmented PAttern Classification with Neural Networks](http://arxiv.org/abs/1505.03229) | arXiv 2015         |         |
| 89.14%  | [Deep Convolutional Neural Networks as Generic Feature Extractors](http://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf) | IJCNN 2015         | Details |
| 89%     | [ImageNet Classification with Deep Convolutional Neural Networks](http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks) | NIPS 2012          | Details |
| 88.80%  | [Empirical Evaluation of Rectified Activations in Convolution Network](http://arxiv.org/pdf/1505.00853.pdf) | ICML workshop 2015 | Details |
| 88.79%  | [Multi-Column Deep Neural Networks for Image Classification](http://www.idsia.ch/~ciresan/data/cvpr2012.pdf) | CVPR 2012          | Details |
| 87.65%  | [ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks](http://arxiv.org/abs/1505.00393) | arXiv 2015         |         |
| 86.70 % | [An Analysis of Unsupervised Pre-training in Light of Recent Advances](http://arxiv.org/abs/1412.6597) | ICLR 2015          | Details |
| 84.87%  | [Stochastic Pooling for Regularization of Deep Convolutional Neural Networks](http://arxiv.org/pdf/1301.3557.pdf) | arXiv 2013         |         |
| 84.4%   | [Improving neural networks by preventing co-adaptation of feature detectors](http://arxiv.org/pdf/1207.0580.pdf) | arXiv 2012         | Details |
| 83.96%  | [Discriminative Learning of Sum-Product Networks](http://papers.nips.cc/paper/4516-discriminative-learning-of-sum-product-networks) | NIPS 2012          |         |
| 82.9%   | [Stable and Efficient Representation Learning with Nonnegativity Constraints](http://jmlr.org/proceedings/papers/v32/line14.pdf) | ICML 2014          | Details |
| 82.2%   | [Learning Invariant Representations with Local Transformations](http://icml.cc/2012/papers/659.pdf) | ICML 2012          | Details |
| 82.18%  | [Convolutional Kernel Networks](http://arxiv.org/abs/1406.3332) | arXiv 2014         | Details |
| 82%     | [Discriminative Unsupervised Feature Learning with Convolutional Neural Networks](http://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf) | NIPS 2014          | Details |
| 80.02%  | [Learning Smooth Pooling Regions for Visual Recognition](http://www.d2.mpi-inf.mpg.de/content/learning-smooth-pooling-regions-visual-recognition) | BMVC 2013          |         |
| 80%     | [Object Recognition with Hierarchical Kernel Descriptors](http://research.cs.washington.edu/istc/lfb/paper/cvpr11.pdf) | CVPR 2011          |         |
| 79.7%   | [Learning with Recursive Perceptual Representations](http://papers.nips.cc/paper/4747-learning-with-recursive-perceptual-representations) | NIPS 2012          | Details |
| 79.6 %  | [An Analysis of Single-Layer Networks in Unsupervised Feature Learning](http://www.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf) | AISTATS 2011       | Details |
| 78.67%  | [PCANet: A Simple Deep Learning Baseline for Image Classification?](http://arxiv.org/abs/1404.3606) | arXiv 2014         | Details |
| 75.86%  | [Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network](http://arxiv.org/abs/1503.04596) | arXiv 2015         | Details |

Something is off, something is missing ? Feel free to [fill in the form](http://rodrigob.github.io/are_we_there_yet/build/new_result_form.html).

# CIFAR-100 who is the best in CIFAR-100 ?

- [![img](http://rodrigob.github.io/are_we_there_yet/build/images/cifar_100.png?1363085077)](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d313030)

### [CIFAR-100](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d313030) 31 results collected

Units: accuracy %

> Classify [32x32 colour images](http://www.cs.toronto.edu/~kriz/cifar.html).

| Result | Method                                                       | Venue              | Details |
| :----- | :----------------------------------------------------------- | :----------------- | :------ |
| 75.72% | [Fast and Accurate Deep Network Learning by Exponential Linear Units](http://arxiv.org/abs/1511.07289) | arXiv 2015         | Details |
| 75.7%  | [Spatially-sparse convolutional neural networks](http://arxiv.org/abs/1409.6070) | arXiv 2014         |         |
| 73.61% | [Fractional Max-Pooling](http://arxiv.org/abs/1412.6071)     | arXiv 2015         | Details |
| 72.60% | [Scalable Bayesian Optimization Using Deep Neural Networks](http://arxiv.org/abs/1502.05700) | ICML 2015          |         |
| 72.44% | [Competitive Multi-scale Convolution](http://arxiv.org/abs/1511.05635) | arXiv 2015         |         |
| 72.34% | [All you need is a good init](http://arxiv.org/abs/1511.06422) | ICLR 2015          | Details |
| 71.14% | [Batch-normalized Maxout Network in Network](http://arxiv.org/abs/1511.02583) | arXiv 2015         | Details |
| 70.80% | [On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units](http://arxiv.org/abs/1508.00330) | arXiv 2015         |         |
| 69.17% | [Learning Activation Functions to Improve Deep Neural Networks](http://arxiv.org/abs/1412.6830) | ICLR 2015          | Details |
| 69.12% | [Stacked What-Where Auto-encoders](http://arxiv.org/abs/1506.02351) | arXiv 2015         |         |
| 68.53% | [Multi-Loss Regularized Deep Neural Network](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343) | CSVT 2015          | Details |
| 68.40% | [Spectral Representations for Convolutional Neural Networks](http://papers.nips.cc/paper/5649-spectral-representations-for-convolutional-neural-networks.pdf) | NIPS 2015          |         |
| 68.25% | [Recurrent Convolutional Neural Network for Object Recognition](http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf) | CVPR 2015          |         |
| 67.76% | [Training Very Deep Networks](http://people.idsia.ch/~rupesh/very_deep_learning/) | NIPS 2015          | Details |
| 67.68% | [Deep Convolutional Neural Networks as Generic Feature Extractors](http://www.isip.uni-luebeck.de/fileadmin/uploads/tx_wapublications/hertel_ijcnn_2015.pdf) | IJCNN 2015         | Details |
| 67.63% | [Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree](http://arxiv.org/abs/1509.08985) | AISTATS 2016       | Details |
| 67.38% | [HD-CNN: Hierarchical Deep Convolutional Neural Network for Large Scale Visual Recognition](https://sites.google.com/site/homepagezhichengyan/home/hdcnn) | ICCV 2015          |         |
| 67.16% | [Universum Prescription: Regularization using Unlabeled Data](http://arxiv.org/abs/1511.03719) | arXiv 2015         |         |
| 66.29% | [Striving for Simplicity: The All Convolutional Net](http://arxiv.org/pdf/1412.6806.pdf) | ICLR 2014          |         |
| 66.22% | [Deep Networks with Internal Selective Attention through Feedback Connections](http://papers.nips.cc/paper/5276-deep-networks-with-internal-selective-attention-through-feedback-connections.pdf) | NIPS 2014          |         |
| 65.43% | [Deeply-Supervised Nets](http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/) | arXiv 2014         | Details |
| 64.77% | [Deep Representation Learning with Target Coding](http://personal.ie.cuhk.edu.hk/~ccloy/files/aaai_2015_target_coding.pdf) | AAAI 2015          |         |
| 64.32% | [Network in Network](http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea) | ICLR 2014          | Details |
| 63.15% | [Discriminative Transfer Learning with Tree-based Priors](http://www.cs.toronto.edu/~nitish/treebasedpriors.pdf) | NIPS 2013          | Details |
| 61.86% | [Improving Deep Neural Networks with Probabilistic Maxout Units](http://openreview.net/document/28d9c3ab-fe88-4836-b898-403d207a037c#28d9c3ab-fe88-4836-b898-403d207a037c) | ICLR 2014          |         |
| 61.43% | [Maxout Networks](http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf) | ICML 2013          | Details |
| 60.8%  | [Stable and Efficient Representation Learning with Nonnegativity Constraints](http://jmlr.org/proceedings/papers/v32/line14.pdf) | ICML 2014          | Details |
| 59.75% | [Empirical Evaluation of Rectified Activations in Convolution Network](http://arxiv.org/pdf/1505.00853.pdf) | ICML workshop 2015 | Details |
| 57.49% | [Stochastic Pooling for Regularization of Deep Convolutional Neural Networks](http://arxiv.org/pdf/1301.3557.pdf) | arXiv 2013         |         |
| 56.29% | [Learning Smooth Pooling Regions for Visual Recognition](http://www.d2.mpi-inf.mpg.de/content/learning-smooth-pooling-regions-visual-recognition) | BMVC 2013          | Details |
| 54.23% | [Beyond Spatial Pyramids: Receptive Field Learning for Pooled Image Features](http://www.eecs.berkeley.edu/~jiayq/assets/pdf/cvpr12_pooling.pdf) | CVPR 2012          |         |

Something is off, something is missing ? Feel free to [fill in the form](http://rodrigob.github.io/are_we_there_yet/build/new_result_form.html).

# STL-10 who is the best in STL-10 ?

- [![img](http://rodrigob.github.io/are_we_there_yet/build/images/stl_10.png?1363085077)](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130)

### [STL-10](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#53544c2d3130) 18 results collected

Units: accuracy %

> Similar to CIFAR-10 but with 96x96 images. [Original dataset website](http://www.stanford.edu/~acoates/stl10/).

| Result           | Method                                                       | Venue          | Details |
| :--------------- | :----------------------------------------------------------- | :------------- | :------ |
| 74.33%           | [Stacked What-Where Auto-encoders](http://arxiv.org/abs/1506.02351) | arXiv 2015     |         |
| 74.10%           | [Convolutional Clustering for Unsupervised Learning](http://arxiv.org/abs/1511.06241) | arXiv 2015     | Details |
| 73.15%           | [Deep Representation Learning with Target Coding](http://personal.ie.cuhk.edu.hk/~ccloy/files/aaai_2015_target_coding.pdf) | AAAI 2015      |         |
| 72.8% (±0.4%)    | [Discriminative Unsupervised Feature Learning with Convolutional Neural Networks](http://papers.nips.cc/paper/5548-discriminative-unsupervised-feature-learning-with-convolutional-neural-networks.pdf) | NIPS 2014      | Details |
| 70.20 % (±0.7 %) | [An Analysis of Unsupervised Pre-training in Light of Recent Advances](http://arxiv.org/abs/1412.6597) | ICLR 2015      | Details |
| 70.1% (±0.6%)    | [Multi-Task Bayesian Optimization](http://hips.seas.harvard.edu/files/swersky-multi-nips-2013.pdf) | NIPS 2013      | Details |
| 68.23% ± 0.5     | [C-SVDDNet: An Effective Single-Layer Network for Unsupervised Feature Learning](http://arxiv.org/abs/1412.7259) | arXiv 2014     |         |
| 68% (±0.55%)     | [Committees of deep feedforward networks trained with few data](http://arxiv.org/abs/1406.5947) | arXiv 2014     |         |
| 67.9% (±0.6%)    | [Stable and Efficient Representation Learning with Nonnegativity Constraints](http://jmlr.org/proceedings/papers/v32/line14.pdf) | ICML 2014      | Details |
| 64.5% (±1%)      | [Unsupervised Feature Learning for RGB-D Based Object Recognition](http://homes.cs.washington.edu/~lfb/paper/iser12.pdf) | ISER 2012      | Details |
| 62.32%           | [Convolutional Kernel Networks](http://arxiv.org/abs/1406.3332) | arXiv 2014     | Details |
| 62.3% (±1%)      | [Discriminative Learning of Sum-Product Networks](http://homes.cs.washington.edu/~rcg/papers/dspn.pdf) | NIPS 2012      |         |
| 61.0% (±0.58%)   | [No more meta-parameter tuning in unsupervised sparse feature learning](http://arxiv.org/abs/1402.5766) | arXiv 2014     |         |
| 61%              | [Deep Learning of Invariant Features via Simulated Fixations in Video](http://papers.nips.cc/paper/4730-deep-learning-of-invariant-features-via-simulated-fixations-in-video) | NIPS 2012 2012 |         |
| 60.1% (±1%)      | [Selecting Receptive Fields in Deep Networks](http://www.stanford.edu/~acoates/papers/coatesng_nips_2011.pdf) | NIPS 2011      |         |
| 58.7%            | [Learning Invariant Representations with Local Transformations](http://web.eecs.umich.edu/~honglak/icml12-invariantFeatureLearning.pdf) | ICML 2012      |         |
| 58.28%           | [Pooling-Invariant Image Feature Learning](http://arxiv.org/pdf/1302.5056v1.pdf) | arXiv 2012     | Details |
| 56.5%            | [Deep Learning of Invariant Features via Simulated Fixations in Video](http://ai.stanford.edu/~wzou/nips_ZouZhuNgYu12.pdf) | NIPS 2012      | Details |

Something is off, something is missing ? Feel free to [fill in the form](http://rodrigob.github.io/are_we_there_yet/build/new_result_form.html).

# SVHN who is the best in SVHN ?

- [![img](http://ufldl.stanford.edu/housenumbers/32x32eg.png)](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#5356484e)

### [SVHN](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#5356484e) 17 results collected

Units: error %

> [The Street View House Numbers (SVHN) Dataset](http://ufldl.stanford.edu/housenumbers).
>
> SVHN is a real-world image dataset for developing machine learning and object recognition algorithms with minimal requirement on data preprocessing and formatting. It can be seen as similar in flavor to MNIST(e.g., the images are of small cropped digits), but incorporates an order of magnitude more labeled data (over 600,000 digit images) and comes from a significantly harder, unsolved, real world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.

| Result | Method                                                       | Venue        | Details |
| :----- | :----------------------------------------------------------- | :----------- | :------ |
| 1.69%  | [Generalizing Pooling Functions in Convolutional Neural Networks: Mixed, Gated, and Tree](http://arxiv.org/abs/1509.08985) | AISTATS 2016 | Details |
| 1.76%  | [Competitive Multi-scale Convolution](http://arxiv.org/abs/1511.05635) | arXiv 2015   |         |
| 1.77%  | [Recurrent Convolutional Neural Network for Object Recognition](http://www.cv-foundation.org/openaccess/content_cvpr_2015/app/2B_004.pdf) | CVPR 2015    | Details |
| 1.81%  | [Batch-normalized Maxout Network in Network](http://arxiv.org/abs/1511.02583) | arXiv 2015   | Details |
| 1.92%  | [Deeply-Supervised Nets](http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/) | arXiv 2014   |         |
| 1.92%  | [Multi-Loss Regularized Deep Neural Network](http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=7258343) | CSVT 2015    | Details |
| 1.94%  | [Regularization of Neural Networks using DropConnect](http://cs.nyu.edu/~wanli/dropc/) | ICML 2013    |         |
| 1.97%  | [On the Importance of Normalisation Layers in Deep Learning with Piecewise Linear Activation Units](http://arxiv.org/abs/1508.00330) | arXiv 2015   |         |
| 2%     | [Estimated human performance](http://ufldl.stanford.edu/housenumbers/nips2011_housenumbers.pdf) | NIPS 2011    | Details |
| 2.15%  | [BinaryConnect: Training Deep Neural Networks with binary weights during propagations](http://papers.nips.cc/paper/5647-binaryconnect-training-deep-neural-networks-with-binary-weights-during-propagations.pdf) | NIPS 2015    |         |
| 2.16%  | [Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks](http://openreview.net/document/0c571b22-f4b6-4d58-87e4-99d7de42a893#0c571b22-f4b6-4d58-87e4-99d7de42a893) | ICLR 2014    | Details |
| 2.35%  | [Network in Network](http://openreview.net/document/9b05a3bb-3a5e-49cb-91f7-0f482af65aea#9b05a3bb-3a5e-49cb-91f7-0f482af65aea) | ICLR 2014    | Details |
| 2.38%  | [ReNet: A Recurrent Neural Network Based Alternative to Convolutional Networks](http://arxiv.org/abs/1505.00393) | arXiv 2015   |         |
| 2.47%  | [Maxout Networks](http://jmlr.org/proceedings/papers/v28/goodfellow13.pdf) | ICML 2013    | Details |
| 2.8%   | [Stochastic Pooling for Regularization of Deep Convolutional Neural Networks](http://arxiv.org/pdf/1301.3557.pdf) | arXiv 2013   | Details |
| 3.96%  | [Enhanced Image Classification With a Fast-Learning Shallow Convolutional Neural Network](http://arxiv.org/abs/1503.04596) | arXiv 2015   | Details |
| 4.9%   | [Convolutional neural networks applied to house numbers digit classiﬁcation](http://yann.lecun.com/exdb/publis/pdf/sermanet-icpr-12.pdf) | ICPR 2012    | Details |

Something is off, something is missing ? Feel free to [fill in the form](http://rodrigob.github.io/are_we_there_yet/build/new_result_form.html).

# ILSVRC2012 task 1 who is the best in ILSVRC2012 task 1 ?

- [![img](http://rodrigob.github.io/are_we_there_yet/build/images/ilsvrc2012_task1.png?1363085077)](http://www.image-net.org/challenges/LSVRC/2012/results.html#t1)

### [ILSVRC2012 task 1](http://www.image-net.org/challenges/LSVRC/2012/results.html#t1)

Units: Error (5 guesses)

> 1000 categories [classification challenge](http://www.image-net.org/challenges/LSVRC/2012/index). With tens of thousands of training, validation and testing images.
>
> See this interesting [comparative analysis](http://www.image-net.org/challenges/LSVRC/2012/analysis/).

Results are collected in the following [external webpage](http://www.image-net.org/challenges/LSVRC/2012/results.html#t1)

Last updated on 2016-02-22.

© 2013-2016 Rodrigo Benenson.

Built using [middleman](http://middlemanapp.com/) and [bootstrap](http://twitter.github.com/bootstrap).